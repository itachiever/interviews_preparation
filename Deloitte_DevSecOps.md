# Job Description:

Role: Application Security Analyst

Application Security / SSDLC


Job Summary:

As an Application Security Analyst with a focus on application security, you will assess projects for security risks and recommend mitigations that enable informed business decisions. You will support the development and enforcement of security controls designed to safeguard Deloitte and our clients’ data across traditional applications and emerging AI/LLM-driven architectures. Your work will support secure design, implementation, and continuous improvement of cloud-native, distributed, and AI-enabled systems.


About the Team:

Deloitte Canada Cybersecurity – Application Security and Engineering team is a group of passionate professionals dedicated to building secure, resilient, and scalable solutions. We thrive on solving complex challenges that safeguard applications across the enterprise. With diverse backgrounds and deep expertise in cybersecurity, secure software development, and risk management, we bring a wealth of knowledge to every project.

As part of this team, you’ll collaborate with engineers and security specialists to embed security into the software development lifecycle, innovate on cutting-edge security practices, and strengthen the firm’s defenses. We are the trusted advisors at the intersection of security and technology—placing you at the forefront of protecting critical systems and enabling secure innovation.


You will have the following responsibilities:

- Conduct application SSDLC reviews, including network security, IAM controls, and application security assessments in a hybrid multi-vendor cloud environment.
- Evaluate application architectures for design flaws—e.g., network segmentation gaps, IAM misconfigurations, overly permissive roles, encryption control deficiencies—against organizational and industry security standards.
- Identify vulnerabilities and weaknesses in the application architecture through application security assessments, code reviews, threat modeling, vulnerability scanning, and penetration testing.
- Collaborate with development teams to integrate automated security scanning tools into the CI/CD pipeline.
- Perform Dynamic Application Security Testing (DAST), Static Application Security Testing (SAST), and Software Composition Analysis (SCA), along with conducting Infrastructure as Code (IaC) reviews.
- Review security scan results and work closely with the development team to prioritize security vulnerabilities identified using a risk-based approach.
- Provide recommendations and guidance to stakeholders to continually improve the security posture of application architectures.
- Work with stakeholders to develop and enhance policies, procedures, and risk management strategies to safeguard clients and enhance overall security.


To succeed in this role, the ideal candidate should possess the following qualifications and skills:

- A Bachelor’s degree in Computer Science, Software Engineering, or Information Security with at least 3 years of industry experience.
- Demonstrated experience in application security concepts such as secure coding, system architecture design, development, industry application security standards, and best practices.
- Proficiency in identifying and remediating common web application vulnerabilities, including OWASP Top 10.
- Understanding of security code issues for JEE/.NET/JS/JSP/ASP/Python applications.
- Competency in understanding complex application environments comprising applications developed on modern technologies such as:
  - Containerization (Docker, Kubernetes, etc.)
  - Serverless compute (Lambda functions, Azure Functions, etc.)
  - Infrastructure as Code (Terraform, CloudFormation, etc.)
  - Automation and CI/CD technologies (Jenkins, Chef, Ansible, Puppet, Azure DevOps, etc.)
- Experience securing AI/LLM systems end-to-end, covering RAG pipelines, vector databases, embeddings, model serving, and access layers; mitigating prompt injection, jailbreaks, unsafe outputs, data poisoning, model inversion/extraction, and sensitive data leakage, while enforcing guardrails, moderation, training data governance, and CI/CD-integrated AI testing.
- Understanding of hardening Agentic AI architectures, including agent/tool frameworks, orchestration, and multi-agent workflows, ensuring secure tool invocation, strict permissions, context isolation, misuse prevention, and safe cloud deployment.
- Demonstrated experience using application security testing tools to perform static and dynamic code analysis, as well as penetration testing.
- Strong hands-on experience assessing multi-vendor cloud environments (AWS, Azure, and GCP), awareness of vendor service offerings, and security evaluation and hardening requirements.
- Experience in software development with solid knowledge of all phases of the SDLC is an asset.
- Ability to effectively articulate application security issues to a broad spectrum of audiences—from developers to project managers to senior leadership—and develop strong relationships across various levels of an organization.
- Strong analytical and problem-solving abilities.
- Strong desire to learn and a career vision of becoming a security architect.


Certifications:

- Desired: Associate or Architect-level certification from a leading cloud vendor (AWS, Azure, or GCP) or working towards OSCP+ Security Engineer.
- Good-to-have / Aspiring: GWAPT or GCPN.


# Questions:

### **Part 1: SSDLC, Architecture & Risk Assessment**

1.  What are the key phases of the **Secure Software Development Lifecycle (SSDLC)**?
2.  How does **Threat Modeling** work, and what frameworks (like STRIDE or PASTA) are used?
3.  What are the common **architectural design flaws** found in hybrid cloud environments?
4.  How is **network segmentation** implemented and assessed in a multi-cloud architecture?
5.  What constitutes an **IAM misconfiguration**, and how does it lead to overly permissive roles?
6.  What are the common **encryption control deficiencies** found in cloud storage solutions?
7.  How are **security risks** balanced against business agility in decision-making?
8.  What is the process for creating and enforcing **Application Security Policies**?

### **Part 2: Cloud Security & Multi-Cloud Environments**

9.  How does **Zero Trust architecture** apply specifically to hybrid multi-cloud environments?
10. What are the unique security challenges of **serverless computing** (e.g., AWS Lambda, Azure Functions)?
11. How are **network security controls** (like Firewalls and NSGs) evaluated across different cloud vendors (AWS, Azure, GCP)?
12. What are the **service-specific hardening requirements** for major cloud providers?
13. How is **identity federation** managed securely across multi-cloud environments?

### **Part 3: Vulnerability Management & Testing (SAST/DAST/SCA)**

14. What are the technical differences between **SAST**, **DAST**, and **SCA**?
15. How are **vulnerabilities prioritized** using a risk-based approach (CVSS, exploitability)?
16. What are the limitations of **automated scanning tools** versus manual penetration testing?
17. How are **false positives** identified and managed in security scan results?
18. What security checks are performed during **Infrastructure as Code (IaC)** reviews?
19. How are **security scanning tools** integrated into CI/CD pipelines (Jenkins, Azure DevOps)?

### **Part 4: Modern Tech (Containers, K8s, Supply Chain)**

20. What are the specific security risks associated with **containerization** (Docker, Kubernetes)?
21. What are **Kubernetes Pod Security Standards** and how do they restrict container capabilities?
22. How is **secrets management** handled in containerized and serverless environments?
23. What is the role of **Software Bill of Materials (SBOM)** in software supply chain security?
24. How are **artifacts signed** to ensure integrity in the deployment pipeline?

### **Part 5: AI/LLM Security (Specialist Focus)**

25. What are the security risks associated with **Retrieval-Augmented Generation (RAG)** pipelines and Vector Databases?
26. What is **Prompt Injection**, and what are the technical mechanisms to mitigate it?
27. How do **Model Inversion** and **Model Extraction** attacks work?
28. What is **Data Poisoning** in the context of Machine Learning training data?
29. How are **Guardrails and Moderation layers** implemented to filter unsafe LLM outputs?
30. What are the security considerations for **Agentic AI architectures**, specifically regarding tool invocation?
31. How is **training-data governance** maintained to ensure privacy and compliance in AI systems?
32. What are the risks of **sensitive data leakage** in LLM applications?

### **Part 6: Secure Coding & Code Review**

33. What are the **OWASP Top 10** vulnerabilities and their impact on modern applications?
34. What are the specific secure coding issues for **.NET and JEE** applications (e.g., Deserialization)?
35. How is **Insecure Direct Object References (IDOR)** identified and mitigated in web apps?
36. What are the dependency management risks in **Python** applications (e.g., pip, PyPI)?
37. How is a secure code review conducted for **microservices architectures**?

### **Part 7: Strategy, Communication & Metrics**

38. How are **technical security risks** articulated effectively to non-technical stakeholders?
39. What **KPIs (Key Performance Indicators)** are used to measure the success of an Application Security program?
40. What is the role of **Third-Party Risk Management** when integrating external APIs?

***
# Answers: 


***

### **Part 1: SSDLC, Architecture & Risk Assessment**

**1. What are the key phases of the Secure Software Development Lifecycle (SSDLC)?**
**Answer:**
Think of the SSDLC as building a house but with safety inspections at every single step.
*   **Requirements:** We decide *what* to build and identify security needs early (e.g., "This room needs a lock").
*   **Design:** We draw the blueprints and check for architectural flaws (e.g., "Don't put the bathroom in the kitchen").
*   **Implementation:** The developers write code following secure standards.
*   **Verification (Testing):** We test the locks and alarms (SAST, DAST, Penetration Testing).
*   **Maintenance:** After the house is built, we monitor it and fix broken windows (patching).
The key difference from a standard lifecycle is that security is involved **from Day 1**, not just at the end.

**2. How does Threat Modeling work, and what frameworks (like STRIDE or PASTA) are used?**
**Answer:**
**Threat Modeling** is essentially a brainstorming session where we try to think like a hacker *before* the code is written. We ask: "If I were the bad guy, how would I break this?"
Common frameworks include:
*   **STRIDE:** This is a mnemonic that helps us find different types of flaws: **S**poofing identity, **T**ampering with data, **R**epudiation (denying an action), **I**nformation disclosure, **D**enial of service, and **E**levation of privilege.
*   **PASTA:** This stands for "Process for Attack Simulation and Threat Analysis." It is more risk-focused, helping us prioritize which threats matter most to the business.

**3. What are the common architectural design flaws found in hybrid cloud environments?**
**Answer:**
These are mistakes in the "blueprint" of the system.
A common flaw is **"Trusting the Hybrid Network."** People often assume that because a server is in their on-premise data center, it’s safe. They open the firewall between the cloud and the data center too wide.
Another flaw is **"Single Points of Failure."** If the bridge connecting your on-prem network to the cloud goes down, your whole application stops. A secure architecture always assumes things will fail and plans for redundancy.

**4. How is network segmentation implemented and assessed in a multi-cloud architecture?**
**Answer:**
**Network Segmentation** is like putting walls inside a castle so if the intruder gets past the gate, they can't get into the treasury.
In the cloud, we use **Virtual Networks (Vnets in Azure, VPCs in AWS)**. We split the network into subnets: one for the public web servers and one for the private databases.
**Assessment:** We check these configurations to ensure there is no "talk" between the public subnet and the private subnet unless strictly necessary. We look for rules that allow traffic from "0.0.0.0/0" (the entire internet) to reach internal databases—that is a critical failure.

**5. What constitutes an IAM misconfiguration, and how does it lead to overly permissive roles?**
**Answer:**
**IAM** stands for Identity and Access Management. A **misconfiguration** is when we give a user or a software service too much power.
For example, imagine a web application that just needs to read pictures from a storage bucket. If we accidentally give it "AdministratorAccess" (God mode) instead of "ReadOnlyAccess," that is a misconfiguration.
If a hacker compromises that app, they now own the whole cloud account because the keys were too permissive. The golden rule is **"Least Privilege"**—give the app only the bare minimum it needs to do its job.

**6. What are the common encryption control deficiencies found in cloud storage solutions?**
**Answer:**
This is about how data is locked away.
A common deficiency is **"Unencrypted Data at Rest."** Sometimes developers forget to turn on the encryption switch for a database or a storage bucket.
Another issue is **"Using Default Keys."** Cloud providers offer to manage keys for you, which is easy, but high-security applications should use **Customer Managed Keys (CMK)**. If you use the cloud provider's default key, their employees *could* theoretically access your data. With CMK, you hold the only key.

**7. How are security risks balanced against business agility in decision-making?**
**Answer:**
This is the art of being a security analyst. We can't just say "No" to everything because the business needs to move fast.
We use a **Risk-Based Approach**. We ask: "What is the likelihood of this happening, and what is the impact?"
*   **High Risk / High Impact:** We stop the line. The feature cannot launch until fixed.
*   **Low Risk / Low Impact:** We might document it and fix it later (technical debt) so the business can launch on time.
We act as a **risk enabler**, not a roadblock. We say, "You can launch this, but you must use these specific security controls to do it safely."

**8. What is the process for creating and enforcing Application Security Policies?**
**Answer:**
A **Security Policy** is the rulebook (e.g., "All code must be scanned," "No passwords in code").
**Creating:** We write the document based on industry standards like OWASP or NIST.
**Enforcing:** This is the hard part. We don't just rely on people reading the PDF. We enforce it using **Automation**. For example, if the policy says "No open storage buckets," we write an automated rule in the cloud that automatically *shuts down* any bucket that becomes open. If the policy says "Code must be scanned," we configure the CI/CD pipeline to fail the build if the scan finds a bug.

***

### **Part 2: Cloud Security & Multi-Cloud Environments**

**9. How does Zero Trust architecture apply specifically to hybrid multi-cloud environments?**
**Answer:**
**Zero Trust** means "Never trust, always verify." In the old days, if you were inside the office network, you were trusted. In Zero Trust, no one is trusted, even if they are inside.
In a **Hybrid Multi-Cloud** environment (e.g., AWS + Azure + On-prem), this is critical. You can't just have one "door." You must verify identity at every step.
*   **Identity:** Every request (user or app) must prove who they are using strong authentication (MFA).
*   **Device:** We check if the laptop or server is healthy and patched.
*   **Least Privilege:** We only give access to the specific data needed, not the whole network.
It treats every cloud provider and every on-prem server as if they were the hostile public internet.

**10. What are the unique security challenges of serverless computing (e.g., AWS Lambda, Azure Functions)?**
**Answer:**
**Serverless** means you don't see the server; you just upload code and it runs. This creates "blind spots."
*   **Perimeterlessness:** There is no server to put a firewall on. Security shifts entirely to the application code and the identity permissions.
*   **Ephemeral Nature:** Functions start and stop in milliseconds. Traditional antivirus tools can't scan them fast enough.
*   **Execution Time:** If a function is compromised, the hacker only has a few seconds to attack before it shuts down, making detection harder.
We secure this by strictly limiting **what the function's identity is allowed to do** (IAM permissions) and validating all input data heavily.

**11. How are network security controls (like Firewalls and NSGs) evaluated across different cloud vendors (AWS, Azure, GCP)?**
**Answer:**
Every cloud vendor uses different names for their firewalls (AWS calls them Security Groups, Azure calls them NSGs, GCP calls them Firewall Rules), but the logic is the same.
We evaluate them by checking for **"Overly Permissive Rules."**
We look for rules that allow traffic from "Anywhere" (0.0.0.0/0) on sensitive ports like Port 22 (SSH) or Port 3389 (RDP). We also check if the rules are documented. If we see a rule allowing traffic from a random IP address with no comment explaining why, that is a red flag that needs to be investigated.

**12. What are the service-specific hardening requirements for major cloud providers?**
**Answer:**
**Hardening** means locking down the default settings to make them more secure.
Every cloud service comes with "insecure defaults" (to make it easy for you to start).
*   **For Storage:** We disable "Public Access" by default.
*   **For Databases:** We enforce "SSL/TLS only" connections (so data can't be sniffed).
*   **For Virtual Machines:** We disable password-based logins and force SSH key-based authentication.
Essentially, we go through a checklist (like the CIS Benchmarks) to ensure every setting is at its most secure level.

**13. How is identity federation managed securely across multi-cloud environments?**
**Answer:**
**Identity Federation** is the ability to use one set of login credentials (like your corporate Microsoft Active Directory) to log into AWS and Google Cloud.
This is managed using protocols like **SAML** or **OIDC**.
The security risk is **"Single Point of Failure."** If a hacker steals the "Federation Keys" or compromises the main admin account in your corporate directory, they suddenly have access to *all* your clouds at once.
To manage this securely, we enforce **Multi-Factor Authentication (MFA)** on the main directory, and we strictly limit who can set up these federation links. We also monitor the logs for any "impossible travel" logins (e.g., logging in from New York and London in the same minute).
